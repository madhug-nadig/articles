---
layout: post
title:  "Parallel Programming in Python with ease"
date:   2017-01-19 02:34:56 +0530
---


Due to the recent [slowdown/possible demise of Moore's law](https://www.technologyreview.com/s/601102/intel-puts-the-brakes-on-moores-law/), parallel programming has gained widespread prominence as the paradigm of the future. Since more than a decade, due to the anticipation of the end of the Moore's law, CPUs with multiple cores have become the norm. Multicore CPU's have also found their way into _smartphones_ too, with [LG Optimus 2X](https://en.wikipedia.org/wiki/LG_Optimus_2X) being the first phone to have multiple cores, way back in 2010. Just switching to the new processor _may no longer guarantee_ faster performance. With multicore/multiprocessor architectures, it is imperative to write software in way that they could be run in parallel. Most computer programs simply cannot take advantage of performance increases offered by GPUs or multi-core CPUs unless those programs are adquately modified. It is time for developers to take a more active role in improving performance by taking the computer architecture into consideration. 

In this post, I will write about parallel programming in `python`.

Parallel programming in Python is a bit _tricky_ as compared to languages such as C/C++ and Java, where one can write parallel programs by executing multiple threads. Python interpreter was designed with simplicity in mind and with the notion that multithreading is [tricky and dangerous](http://www.softpanorama.org/People/Ousterhout/Threads/index.shtml).  The default python(CPython) interpreter has a thread-safe mechanism, the **Global interpreter lock**. 

>Global interpreter lock (GIL) is a mechanism used in computer language interpreters to synchronize the execution of threads so that only one native thread can execute at a time. An interpreter that uses GIL always allows exactly one thread to execute at a time, even if run on a multi-core processor. 

**Python is restricted to a single OS thread**; therefore, it cannot make use of the multiple cores and processors available on modern hardware. So _throwing some threads_ into the program will not result in faster performance, since the threads essentially run in serial. This problem only exists in CPython, not in JPython or IronPython.

 
## The `multiprocessing` library

Instead of threads, Python programmers should use the [`multiprocessing`](http://docs.python.org/3/library/multiprocessing.html?highlight=multiprocessing#multiprocessing) library to easily create and coordinate multiple Python processes. Each one is scheduled independently on the CPU by the OS. Multiprocessing is an invaluable library for writing parallel programs in python. 

>The multiprocessing module aims at providing a simple API for the use of parallelism
based on processes

>The approach that is based on processes is very popular within the Python users' community as it is an alternative to answering questions on the use of CPU-Bound threads and GIL
present in Python.

From what I gather from the internet, this programming model is easier than parallelism with threads and by far the most popular soultion to parallel programming in python. Multiprocessing is ideal for **CPU bound tasks**.

The multiprocessing module has been in the Python Standard Library since Python 2.6. 
It is important to understand that in multiprocessing, it's the process level abstraction, not thread level. 

> The multiprocessing package offers both local and remote concurrency, effectively side-stepping the Global Interpreter Lock by using subprocesses instead of threads.

The multiprocessing module only allows message passing paradigm for inter-process.

>The message passing paradigm is based on the lack of synchronizing mechanisms as copies
of data are exchanged among processes.

### `Process`

In multiprocessing, new processes are spawned by creating a `Process` object and then calling its `start()` method. The processes can be ended by using the `join()` method.

In a simple example, I will parallel compute a rudimentary calculation. I will compute the square root of the cube of the first 7 positive integers **parallely** using the `Process` class. A new process is spawned for each argument(_definately_ not scalable, but a good enough example), so this case, we will have 7 subprocesses in parallel.
    
    import multiprocessing as mp
    import math
    
    
    def cubes_and_sqare_root(a, order,output):
    	output.put((int(order), math.sqrt(a**3)))
    
    def main():
    	#Using the queue as the message passing paradigm 
    	output = mp.Queue()
    	processes = [mp.Process(target=cubes_and_sqare_root, args=(x, x,output)) for x in range(1,8)]
    
    	for process in processes:
    		process.start()
    
    	for process in processes:
    		process.join()
    
    	results = [output.get() for process in processes]
    
    	print(results)

    if __name__ == '__main__':
    	main()

Typically, the order of output cannot be predicted as one subprocess may take longer time than another.

The output:

`>>>[(2, 2.8284271247461903)(4, 8.0)(1, 1.0)(3, 5.196152422706632)(6, 14.696938456699069)(5, 11.180339887498949)(7, 18.520259177452136)]`

Let's print out the details of all the subprocesses involved in the above computation:

    import os
    
	def process_info():
		print('Module:', __name__, '\n')
        print('Parent Process id:', os.getppid(), '\n')
        print('Process id:', os.getpid(), '\n\n')

The output in exact order:

    Module:__mp_main__
    Parent Process id:23524
    Process id:22928
    
    Module:__mp_main__
    Parent Process id:23524
    Process id:24604
    
    Module:__mp_main__
    Parent Process id:23524
    Process id:11584
    
    Module:__mp_main__
    Parent Process id:23524
    Process id:23472
    
    Module:__mp_main__
    Parent Process id:23524
    Process id:9068
    
    Module:__mp_main__
    Parent Process id:23524
    Process id:24636
    
    Module:__mp_main__
    Parent Process id:23524
    Process id:23964

From the above output, it is apparent that 7 subprocesses were spawned by the same parent process, through multiprocessing. You can find the entire sample code related to the above program, [here](https://github.com/madhug-nadig/Parallel-Processing-Nadig/blob/master/Python%20multiprocessing%20example-%20Process.py)

### `Pool`

>The Pool class represents a pool of worker processes. It has methods which allows tasks to be offloaded to the worker processes in a few different ways.

